{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Awokose:\n",
    "    \n",
    "    def __init__(self, chrome_path=None, prefs=None, filename=None, unallowed_tokens=None, source_to_start_from=None, page_to_start_from=None, article_to_start_from=None):\n",
    "        \n",
    "        self.page_to_start_from = page_to_start_from or 0\n",
    "        self.article_to_start_from = article_to_start_from or 0\n",
    "        self.source_to_start_from = source_to_start_from or 0\n",
    "        #self.article_xpath_number = 3\n",
    "        \n",
    "        self.sources = [\"https://www.hausaloaded.com/search/label/Wasanni\",\n",
    "                        \"https://www.hausaloaded.com/search/label/Labarai\",\n",
    "                        \"https://www.hausaloaded.com/search/label/Politics%20Musics\",\n",
    "                        \"https://www.hausaloaded.com/search/label/Fadakarwa\",\n",
    "                        \"https://www.hausaloaded.com/search/label/kannywood\"\n",
    "                       ]\n",
    "        \n",
    "        self.driver = None\n",
    "        self.chrome_path = chrome_path or 'C:\\\\Users\\\\NiniolaAdegboyega\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe'\n",
    "        # disable images in browser. For faster loading. \n",
    "        self.prefs = prefs or {\"profile.managed_default_content_settings.images\" : 2}\n",
    "        \n",
    "        #self.article_path = \"/html/body/div[3]/div[3]/div/div[2]/div/div[1]/div[{}]/div/div/article/div[3]/div[2]/a\"\n",
    "        self.load_more_button_path = '//*[@id=\"Blog1_blog-pager-older-link\"]'\n",
    "        \n",
    "        self.filename = filename or \"../data/hausaloaded/hausaloaded.com_{}_{}_{}_{}.txt\".format(\n",
    "            time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "            self.source_to_start_from,\n",
    "            self.page_to_start_from,\n",
    "            self.article_to_start_from\n",
    "        )\n",
    "        self.file = open(self.filename, \"w+\", encoding=\"utf-8\")\n",
    "        \n",
    "        \n",
    "    def init_driver(self):\n",
    "        \"\"\"\n",
    "        This func initializes the webdriver and disables images\n",
    "        A wait is initialized with a 5 second timeout\n",
    "        \"\"\"\n",
    "        options = Options()\n",
    "        options.add_experimental_option(\"prefs\", self.prefs)\n",
    "\n",
    "        driver = webdriver.Chrome(self.chrome_path, options=options)\n",
    "        # define a generic wait to be used throughout\n",
    "        driver.wait = WebDriverWait(driver, 5)\n",
    "\n",
    "        return driver\n",
    "    \n",
    "    def __check_no_of_articles(self):\n",
    "        \"\"\"\n",
    "        This func checks number of articles on a page\n",
    "        \"\"\"\n",
    "        content = self.driver.page_source\n",
    "        soup = bs(content)\n",
    "        no_articles_on_page = len(soup.find_all('h2', attrs={'class': 'post-title entry-title'}))\n",
    "        return no_articles_on_page\n",
    "        \n",
    "    def __write_article_to_text(self, sentences):\n",
    "        \"\"\"\n",
    "        This func writes individual sentences to a file\n",
    "        \"\"\"\n",
    "        # split into individual sentences\n",
    "        sentence_split = filter(None, sentences.split(\".\"))\n",
    "        # write each individual sentences on a new line\n",
    "        for s in sentence_split:\n",
    "            self.file.write(s.strip() + \"\\n\")\n",
    "            \n",
    "    def __on_article_action(self):\n",
    "        \"\"\"\n",
    "        This func calls __write_article_to_text on individual paragraphs of the article\n",
    "        The paragraphs are in different divs\n",
    "        \"\"\"\n",
    "        content = self.driver.page_source\n",
    "        soup = bs(content)\n",
    "        \n",
    "        for paragraph in soup.find_all('div', attrs={'class':\"post-body entry-content\"}):\n",
    "            self.__write_article_to_text(paragraph.text)\n",
    "    \n",
    "    def __scroll_to_article_range(self):\n",
    "        \"\"\"\n",
    "        To avoid ElementNotInteractable error, this func scrolls article into view\n",
    "        before any article action begins\n",
    "        \"\"\"\n",
    "        while self.page_to_start_from > 1:\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView();\",\n",
    "                                       self.driver.find_element_by_xpath(self.load_more_button_path)\n",
    "                                      )\n",
    "            self.driver.find_element_by_xpath(self.load_more_button_path).click()\n",
    "            time.sleep(1)\n",
    "            self.page_to_start_from -= 1\n",
    "\n",
    "    def __open_article_on_new_page_and_collect(self, href):\n",
    "        \"\"\"\n",
    "        This func open an individual article in a new window and calls\n",
    "        functions to collect the text. \n",
    "        \"\"\"\n",
    "        #link = self.driver.find_element_by_xpath(self.article_path.format(\n",
    "            #self.article_xpath_number)).get_attribute(\"href\")\n",
    "        #print(link)\n",
    "        self.driver.execute_script(\"window.open('{}')\".format(href))\n",
    "        \n",
    "        windows = self.driver.window_handles\n",
    "        self.driver.switch_to.window(windows[1])\n",
    "        \n",
    "        self.__on_article_action()\n",
    "        self.article_to_start_from += 1\n",
    "        \n",
    "        self.driver.close()\n",
    "        self.driver.switch_to.window(windows[0])\n",
    "        \n",
    "    def __collect_page(self):\n",
    "        \"\"\"\n",
    "        This func loops over all articles on a page, opens each\n",
    "        in a new window and writes its text to file. \n",
    "        \"\"\"\n",
    "        # initialize empty list to hold hrefs\n",
    "        href_list = list()\n",
    "        \n",
    "        # collect all hrefs\n",
    "        for element in self.driver.find_elements_by_class_name(\"readmore2\"):\n",
    "            href_list.append(element.get_attribute(\"href\"))\n",
    "            \n",
    "        #print(href_list)\n",
    "        \n",
    "        # loop over hrefs and collect articles\n",
    "        for href in href_list[self.article_to_start_from:]:\n",
    "            self.__open_article_on_new_page_and_collect(href)\n",
    "            time.sleep(1)\n",
    "            \n",
    "        \"\"\"no_articles_on_page = self.__check_no_of_articles()\n",
    "        self.article_xpath_number = 3 \n",
    "        while self.article_xpath_number <= no_articles_on_page:\n",
    "            print(self.article_xpath_number)\n",
    "            if self.article_xpath_number > 4:\n",
    "                \"\"\"\n",
    "            \n",
    "            #self.driver.find_element_by_xpath(self.article.format(self.article_xpath_number))\n",
    "            \n",
    "            #self.article_xpath_number += 1\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        This func loops over the different sources of the website\n",
    "        and uses the previous functions to collect text of all articles.\n",
    "        Where error occurs at a particular article, the article number is \n",
    "        stored and the loop continues to the next source. \n",
    "        \"\"\"\n",
    "        self.driver = self.init_driver()\n",
    "        \n",
    "        for source in self.sources[self.source_to_start_from:]:\n",
    "            print(\"Starting Source {}\".format(source))\n",
    "            self.driver.get(source)\n",
    "            if self.page_to_start_from:\n",
    "                self.__scroll_to_article_range()\n",
    "            \n",
    "            while True:\n",
    "                self.__collect_page()\n",
    "                self.article_to_start_from = 0 # reinitialize article_to_start_from\n",
    "                self.page_to_start_from += 1 # increment the number of pages collected\n",
    "                \n",
    "                try:\n",
    "                    # scroll Next button into view and click it\n",
    "                    self.driver.execute_script(\"arguments[0].scrollIntoView();\", \n",
    "                                           self.driver.find_element_by_xpath(self.load_more_button_path)\n",
    "                                              )\n",
    "                    time.sleep(1)\n",
    "                    self.driver.find_element_by_xpath(self.load_more_button_path).click()\n",
    "                except Exception as e:\n",
    "                    print(\"Error occured at Source {} Page {} Article {}\".format(self.sources.index(source),\n",
    "                                                                                 self.page_to_start_from, \n",
    "                                                                                 self.article_to_start_from))\n",
    "                    break\n",
    "                    #raise e\n",
    "    \n",
    "                time.sleep(1)\n",
    "            self.page_to_start_from = 0 # reinitialize page_to_start_from\n",
    "        # close file & driver\n",
    "        self.file.close()\n",
    "        self.driver.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "awks = Awokose(source_to_start_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Source https://www.hausaloaded.com/search/label/Fadakarwa\n",
      "Error occured at Source 3 Page 5 Article 0\n",
      "Starting Source https://www.hausaloaded.com/search/label/kannywood\n",
      "Error occured at Source 4 Page 111 Article 0\n"
     ]
    }
   ],
   "source": [
    "awks.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
