{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    \"https://www.wattpad.com/627607959-matar-waye-1-10\",\n",
    "    \"https://www.wattpad.com/783423722-ummulkhair-%F0%9F%91%A9%E2%80%8D%F0%9F%91%A7%F0%9F%92%9D%F0%9F%91%A8%E2%80%8D%F0%9F%91%A7-part-1\",\n",
    "    \"https://www.wattpad.com/435279154-khairat-1\",\n",
    "    \"https://www.wattpad.com/438014700-sanadin-ki-rayuwarmu-da-suhailat\",\n",
    "    \"https://www.wattpad.com/769019871-rashin-dace-introduction\",\n",
    "    \"https://www.wattpad.com/664888317-auren-dole-2015-part-1\",\n",
    "    \"https://www.wattpad.com/606963558-zuciyar-mutum-birninsa-1~fitila\",\n",
    "    \"https://www.wattpad.com/308506210-yar-kurma-comple%E2%88%9A-yar-kurma\",\n",
    "    \"https://www.wattpad.com/459645599-nadamar-rayuwata-complt-babi-na-daya\",\n",
    "    \"https://www.wattpad.com/635667144-kundin-haske%F0%9F%92%A1\",\n",
    "    \"https://www.wattpad.com/453600216-idan-ka-daka-ta-bado-complt-babi-na-%27daya\",\n",
    "    \"https://www.wattpad.com/559513141-jasmine-baturiyya-ce-%F0%9F%8C%B7jasmine%F0%9F%8C%B7\",\n",
    "    \"https://www.wattpad.com/392145778-gimbiya-zajlat-cmplt-gimbiya-zajlat-babi-na-%27daya\",\n",
    "    \"https://www.wattpad.com/804845120-bakar-zargi%F0%9F%96%A4%F0%9F%96%A4a-hausa-love-story%F0%9F%96%A4%F0%9F%96%A4-completed\",\n",
    "    \"https://www.wattpad.com/556381904-sarauniya-jidda-na-aunty-fyn-love-story-babi-na\",\n",
    "    \"https://www.wattpad.com/790747730-wadata-one\",\n",
    "    \"https://www.wattpad.com/714141565-abadan\",\n",
    "    \"https://www.wattpad.com/660395766-dabaibayi-samira\",\n",
    "    \"https://www.wattpad.com/595953677-maraicin-%27ya-mace-gabatarwa\",\n",
    "    \"https://www.wattpad.com/746258113-hauwa\",\n",
    "    \"https://www.wattpad.com/425157222-akwai-lokaci-babi-na-daya\",\n",
    "    \"https://www.wattpad.com/762844517-uwa-ta-gari-prolong\",\n",
    "    \"https://www.wattpad.com/729342139-amsoshin-tambayoyinku-tambayoyi-da-amsoshi\",\n",
    "    \"https://www.wattpad.com/764388392-kambun-sadaukantaka\",\n",
    "    \"https://www.wattpad.com/776122898-yuhaina%F0%9F%92%96-notice\",\n",
    "    \"https://www.wattpad.com/482828599-kaine-muradina-gabatarwa\",\n",
    "    \"https://www.wattpad.com/754111276-abuncin-wani-page-one\",\n",
    "    \"https://www.wattpad.com/751834446-zabina-part-2-complete-hausanovel\",\n",
    "    \"https://www.wattpad.com/606671070-nadamar-rayuwa-wasikar-farko\",\n",
    "    \"https://www.wattpad.com/781711723-rashin-uba-shafi-na-1\",\n",
    "    \"https://www.wattpad.com/619040718-nainah-1-5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, StaleElementReferenceException, ElementNotInteractableException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk import tokenize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = 'C:\\\\Users\\\\AkintundeOladipo\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe'\n",
    "comment_xpath = \"/html/body/div[4]/div/main/article/footer/div[1]/div[3]/div[1]/div/div/div/section/div/div[3]/button/span[1]/span[2]\"\n",
    "chapter_xpath = \"/html/body/div[4]/div/div[1]/div/div[1]/div/ul/li[{}]/a/div\"\n",
    "\n",
    "def init_driver():\n",
    "    \n",
    "    driver = webdriver.Chrome(chrome_path)\n",
    "    \n",
    "    # define a generic wait to be used throughout\n",
    "    driver.wait = WebDriverWait(driver, 5)\n",
    "    \n",
    "    # dataframe for a possible sentiment analysis\n",
    "    # storage = pd.DataFrame(columns=[\"source\", \"no_chapters\", \"chapter_titles\", \"tags\", \"text\", \"interactions\", \"comments\"])\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def show_all_comments(comment_xpath):\n",
    "    \"\"\"\n",
    "    Shows all comments existing on storage page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.find_element_by_xpath(comment_xpath).click()\n",
    "        driver.implicitly_wait(10)\n",
    "        # driver.find_element_by_tag_name('html').send_keys(Keys.END)\n",
    "        scroll(driver, 5)\n",
    "    except ElementClickInterceptedException:\n",
    "        \"\"\"\n",
    "        if element is still covered by another element because page\n",
    "        is loading, wait\n",
    "        \"\"\"\n",
    "        driver.wait.until(EC.visibility_of_element_located((By.XPATH, comment_xpath)))\n",
    "    except (ElementNotInteractableException, NoSuchElementException):\n",
    "        \"\"\"\n",
    "        if element does not exist or is now hidden, exit. \n",
    "        \"\"\"\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def remove_emojis(input_string):\n",
    "    \"\"\"\n",
    "    This func removes emojis from text\n",
    "    \"\"\"\n",
    "    return input_string.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "def close_driver(driver):\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "def to_txt(sentences, file):\n",
    "    \"\"\"\n",
    "    This func writes a list of sentences into a file line by line.\n",
    "    \"\"\"\n",
    "    sentence_split = filter(None, sentences.split(\".\"))\n",
    "    \n",
    "    for s in sentence_split:\n",
    "        #print(s.strip())\n",
    "        file.write(s.strip() + \"\\n\")\n",
    "        \n",
    "def init_storage():\n",
    "    \"\"\"\n",
    "    This func creates unique dataframes for stories\n",
    "    collected from different sources\n",
    "    \"\"\"\n",
    "    storage = pd.DataFrame(columns=[\"source\",\"chapter_titles\", \n",
    "                                    \"tags\", \"text\", \n",
    "                                    \"interactions\", \"comments\"])\n",
    "    \n",
    "    # initialize empty list to hold entities to be collected\n",
    "    comments = list()\n",
    "    \n",
    "    return storage, comments\n",
    "\n",
    "def scroll(driver, timeout):\n",
    "    \"\"\"\n",
    "    This func scrolls to the bottom of the Hausa\n",
    "    Writers Series page.\n",
    "    \"\"\"\n",
    "    \n",
    "    scroll_pause_timeout = timeout\n",
    "    \n",
    "    # get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # wait for page to load\n",
    "        time.sleep(scroll_pause_timeout)\n",
    "        \n",
    "        # calculate new scroll height & compare with previous\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break # bottom has been reached\n",
    "        \n",
    "        last_height = new_height\n",
    "    \n",
    "def download_stories(driver, sources):\n",
    "    \n",
    "    interaction_types = [\"reads\", \"likes\", \"comments\"]\n",
    "    \n",
    "    for i, source in enumerate(sources):\n",
    "        \n",
    "        print(f\"Starting Source {i}\")\n",
    "        \n",
    "        filename = \"../data/wattpad/Source_{0}.txt\"\n",
    "        file = open(filename.format(i), \"w+\", encoding=\"utf-8\")\n",
    "        \n",
    "        # Source must be link of first chapter of story\n",
    "        driver.get(source)\n",
    "        \n",
    "        # initializes dataframe and list to store data\n",
    "        #storage, comments = init_storage()\n",
    "        \n",
    "        time.sleep(2) \n",
    "        \n",
    "        # finds Table of Contents on page\n",
    "        driver.find_element_by_css_selector('.btn.btn-toc.dropdown-toggle').click()\n",
    "        \n",
    "        # grabs number of chapters and their titles\n",
    "        options = driver.find_element_by_css_selector(\".dropdown-menu.pull-left > ul\")\n",
    "        chapter_titles = options.text.split(\"\\n\")\n",
    "        \n",
    "        # write the chapter titles \n",
    "        #storage.loc[:, \"chapter_titles\"] = chapter_titles\n",
    "        n_chapters = len(chapter_titles) \n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        driver.find_element_by_css_selector('.btn.btn-toc.dropdown-toggle').click()\n",
    "        \n",
    "        # loops over the chapters collecting entities into the dataframe and text file.\n",
    "        # loop starts from 1 because \n",
    "        for chapter in range(1, n_chapters+1):\n",
    "            # print(chapter)\n",
    "            # driver.refresh()\n",
    "            #body_of_story = \"\"\n",
    "            # initialize list to hold texts\n",
    "            #text = list()\n",
    "            #comments = list()\n",
    "            \n",
    "            if chapter != 1:\n",
    "                # wait for dropdown to show before selecting \n",
    "                driver.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".btn.btn-toc.dropdown-toggle\")))\n",
    "                driver.find_element_by_css_selector('.btn.btn-toc.dropdown-toggle').click()\n",
    "\n",
    "                # wait for chapter in focus to show before selecting\n",
    "                driver.wait.until(EC.presence_of_element_located((By.XPATH, chapter_xpath.format(chapter))))\n",
    "                driver.find_element_by_xpath(chapter_xpath.format(chapter)).click()\n",
    "            \n",
    "            # go to bottom of page\n",
    "            time.sleep(2)\n",
    "            \n",
    "            #html = driver.find_element_by_tag_name('html')\n",
    "            #html.send_keys(Keys.END)\n",
    "            \n",
    "            scroll(driver, 2)\n",
    "            \n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Show all comments            \n",
    "            while show_all_comments(comment_xpath):\n",
    "                \n",
    "                time.sleep(2)\n",
    "                driver.find_element_by_tag_name('html').send_keys(Keys.END)\n",
    "                time.sleep(2)\n",
    "\n",
    "                show_all_comments(comment_xpath)\n",
    "            \n",
    "            #time.sleep(5)\n",
    "            try:\n",
    "                content = driver.page_source\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            soup = bs(content)\n",
    "            \n",
    "            #storage.loc[chapter-1, \"interactions\"] = str({k:v for k, v in zip(interaction_types, \n",
    "                                                                                #soup.findAll('div', attrs={'class': \"story-stats\"\n",
    "                                                                                                          #})[0].text.split())})\n",
    "            #print(str({k:v for k, v in zip(interaction_types, \n",
    "                                           #soup.findAll('div', attrs={'class': \"story-stats\"\n",
    "                                                                     #})[0].text.split())}))\n",
    "            to_txt(remove_emojis(soup.title.text), file)\n",
    "            \n",
    "            # collect both title and body of story \n",
    "            for j, options in enumerate(soup.findAll('p', {\"data-p-id\": True})):\n",
    "\n",
    "                # convert to sentences and add it to our list of sentences\n",
    "                to_txt(remove_emojis(options.text), file)\n",
    "                #body_of_story += options.text + \"\\n\"\n",
    "                \n",
    "            #storage.loc[chapter-1, \"text\"] = body_of_story\n",
    "                    \n",
    "            # loop over comment class and append to list\n",
    "            file.write(\" - Comments - \\n\")\n",
    "            for comment in soup.findAll('div', attrs={'class': \"comment\"}):\n",
    "                \n",
    "                to_txt(comment.find('pre').text, file)\n",
    "                \n",
    "            # write collected sentences into file\n",
    "            #to_txt(text, file)    \n",
    "            #to_txt(comments, file)\n",
    "            \n",
    "            # print(comments)\n",
    "            # write comments to dataframe as str    \n",
    "            #storage.loc[chapter-1, \"comments\"] = str(comments)\n",
    "                \n",
    "            # when you get to the last chapter, write out the tags and source for the story.\n",
    "            # These do not change with chapter. \n",
    "            #if chapter == n_chapters:\n",
    "                \n",
    "                #tags.extend([tag.text for tag in soul.findAll('p', attrs={'class': \"item-tags\"})])\n",
    "                #storage.loc[:, \"tags\"] = [tag.text for tag in soup.findAll('p', attrs={'class': \"item-tags\"})] * storage.shape[0]\n",
    "                \n",
    "                # write the source on every row \n",
    "                #storage.loc[:, \"source\"] = source \n",
    "                \n",
    "            time.sleep(2)\n",
    "                \n",
    "        #storage.to_csv(f\"Source_{i}.csv\")\n",
    "        file.close()\n",
    "        print(f\"Finished Source no. {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Source 0\n",
      "Finished Source no. 0\n",
      "Starting Source 1\n",
      "Finished Source no. 1\n",
      "Starting Source 2\n",
      "Finished Source no. 2\n",
      "Starting Source 3\n",
      "Finished Source no. 3\n",
      "Starting Source 4\n",
      "Finished Source no. 4\n",
      "Starting Source 5\n",
      "Finished Source no. 5\n",
      "Starting Source 6\n",
      "Finished Source no. 6\n",
      "Starting Source 7\n",
      "Finished Source no. 7\n",
      "Starting Source 8\n",
      "Finished Source no. 8\n",
      "Starting Source 9\n",
      "Finished Source no. 9\n",
      "Starting Source 10\n",
      "Finished Source no. 10\n",
      "Starting Source 11\n",
      "Finished Source no. 11\n",
      "Starting Source 12\n",
      "Finished Source no. 12\n",
      "Starting Source 13\n",
      "Finished Source no. 13\n",
      "Starting Source 14\n",
      "Finished Source no. 14\n",
      "Starting Source 15\n",
      "Finished Source no. 15\n",
      "Starting Source 16\n",
      "Finished Source no. 16\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    driver = init_driver()\n",
    "    \n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    download_stories(driver, sources)\n",
    "    \n",
    "    print(\"All done!\")\n",
    "    \n",
    "    close_driver(driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showcode": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
